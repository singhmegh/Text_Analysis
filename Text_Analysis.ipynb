{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20a0e8bf-303e-4d84-8868-75ac89ac7e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import re \n",
    "import os \n",
    "import pandas as pd\n",
    "from nltk.tokenize import RegexpTokenizer , sent_tokenize\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c344d88-0d6b-4a07-977b-98335d3c25dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36\"\n",
    "}\n",
    "response = requests.get(\"https://example.com\", headers=headers)\n",
    "print(response.status_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2cecb77b-b643-4715-8c7e-cc9c77fdd1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "stopWordsFile =     \"C:/Users/sumit/Downloads/StopWords-20250923T151456Z-1-001/StopWords/StopWords_Auditor.txt\"\n",
    "positiveWordsFile = \"C:/Users/sumit/Downloads/MasterDictionary-20250923T151506Z-1-001/MasterDictionary/positive-words.txt\"\n",
    "nagitiveWordsFile = \"C:/Users/sumit/Downloads/MasterDictionary-20250923T151506Z-1-001/MasterDictionary/negative-words.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8b2cf113-7c70-4e6d-8b6f-b621fa3b682a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ai and ml based youtube analytics and content creation tool for optimizing subscriber engagement and content strategy',\n",
       " 'enhancing front end features and functionality for improved user experience and dashboard accuracy in partner hospital application',\n",
       " 'roas dashboard for campaign wise google ads budget tracking using google ads ap',\n",
       " 'efficient processing and analysis of financial data from pdf files addressing formatting inconsistencies and ensuring data integrity for a toyota dealership management firm',\n",
       " 'development of ea robot for automated trading',\n",
       " 'ai and ml based youtube analytics and content creation tool for optimizing subscriber engagement and content strategy',\n",
       " 'enhancing front end features and functionality for improved user experience and dashboard accuracy in partner hospital application',\n",
       " 'roas dashboard for campaign wise google ads budget tracking using google ads ap',\n",
       " 'efficient processing and analysis of financial data from pdf files addressing formatting inconsistencies and ensuring data integrity for a toyota dealership management firm',\n",
       " 'transforming and managing a large scale sql pedigree database to neo4j graph db',\n",
       " 'enhancing model accuracy from 58 to over 90 strategies for improving predictive performance',\n",
       " 'securing sensitive financial data with privacy preserving machine learning for predictive analytics',\n",
       " 'enhancing data collection for research institutions addressing survey fatigue and incorporating verbal communication for richer insights',\n",
       " 'analyzing the impact of positive emotions and pandemic severity on mental health and resilience among entrepreneurs insights and predictive modeling',\n",
       " 'dynamic brand centric dashboard for automotive dealerships pdf to financial insights with flask react architecture and aws cloud hosting',\n",
       " 'cloud based data modeling and analysis platform with drag and drop interface and openai api integration for simulation insights',\n",
       " 'voter profile analysis and search application for targeted campaign engagement using government voter data',\n",
       " 'bert based classification of individuals and organizations into two categories using natural language processing',\n",
       " 'comprehensive analysis of solana and ethereum contributors using github api with comparative study of 1000 random github profiles',\n",
       " 'powerbi rest api fetching dataflow and refresh schedules with semantic models',\n",
       " 'automated job data import and management solution for enhanced efficiency',\n",
       " 'data analytics and optimization solution for enhancing renewable energy efficiency',\n",
       " 'time series analysis and trend forecasting solution for predicting news trends',\n",
       " 'advanced data visualization solutions for monitoring key business metrics with integrated interactive dashboards',\n",
       " 'advanced patient data analysis solution for trend identification and improved healthcare outcome',\n",
       " 'anomaly detection and analysis for enhanced data integrity and user experience on bright datas website',\n",
       " 'building custom tflite models and benchmarking on voxl2 chips',\n",
       " 'sports prediction model for multiple sports leagues',\n",
       " 'efficient coach allocation system for sports coaching organization',\n",
       " 'data studio dashboard with a data pipeline tool synced with podio using custom webhooks and google cloud function 2',\n",
       " 'ai driven backend for audio to text conversion and analytical assessment in pharmaceutical practice',\n",
       " 'cloud based web application for financial data processing and visualization of sp 500 metrics',\n",
       " 'department wise kpi tracking dashboard with technician performance analysis for atoz dependable service',\n",
       " 'steps to convert a node js api to python for aws lambda deployment',\n",
       " 'building an analytics dashboard with a pdf parsing pipeline for data extraction',\n",
       " 'building a real time log file visualization dashboard in kibana',\n",
       " 'analyzing the impact of female ceo appointments on company stock prices',\n",
       " 'ai chatbot using llm langchain llama',\n",
       " 'healthcare ai chatbot using llama llm langchain',\n",
       " 'ai bot audio to audio',\n",
       " 'recommendation engine for insurance sector to expand business in the rural area',\n",
       " 'data from crm via zapier to google sheets dynamic to powerbi',\n",
       " 'data warehouse to google data studio looker dashboard',\n",
       " 'crm monday com via zapier to power bi dashboard',\n",
       " 'monday com to kpi dashboard to manage view and generate insights from the crm data',\n",
       " 'data management for a political saas application',\n",
       " 'google lsa ads google local service ads etl tools and dashboards',\n",
       " 'ad networks marketing campaign data dashboard in looker google data studio',\n",
       " 'analytical solution for a tech firm',\n",
       " 'ai solution for a technology information and internet firm',\n",
       " 'ai and nlp based solutions to automate data discovery for venture capital and private equity principals',\n",
       " 'an etl solution for an internet publishing firm',\n",
       " 'ai based algorithmic trading bot for forex',\n",
       " 'equity waterfalls model based saas application for real estate sector',\n",
       " 'ai solutions for foreign exchange an automated algo trading tool',\n",
       " 'ai agent development and deployment in jina ai',\n",
       " 'golden record a knowledge graph database approach to unfold discovery using neo4j',\n",
       " 'advanced ai for trading automation',\n",
       " 'create a knowledge graph to provide real time analytics recommendations and a single source of truth',\n",
       " 'advanced ai for thermal person detection',\n",
       " 'advanced ai for road cam threat detection',\n",
       " 'advanced ai for pedestrian crossing safety',\n",
       " 'handgun detection using yolo',\n",
       " 'using graph technology to create single customer view',\n",
       " 'car detection in satellite images',\n",
       " 'building a physics informed neural network for circuit evaluation',\n",
       " 'connecting mongodb database to power bi dashboard dashboard automation',\n",
       " 'data transformation',\n",
       " 'e commerce store analysis purchase behavior ad spend conversion traffic etc',\n",
       " 'kpi dashboard for accountants',\n",
       " 'return on advertising spend dashboard marketing automation and analytics using etl and dashboard',\n",
       " 'ranking customer behaviours for business strategy',\n",
       " 'algorithmic trading for multiple commodities markets like forex metals energy etc',\n",
       " 'trading bot for forex',\n",
       " 'python model for the analysis of sector specific stock etfs for investment purposes%ef%bf%bc',\n",
       " 'medical classification',\n",
       " 'design develop bert question answering model explanations with visualization',\n",
       " 'design and develop solution to anomaly detection classification problems',\n",
       " 'an etl solution for currency data to google big query',\n",
       " 'etl and mlops infrastructure for blockchain analytics',\n",
       " 'an agent based model of a virtual power plant vpp',\n",
       " 'transform api into sdk library and widget',\n",
       " 'integration of a product to a cloud based crm platform',\n",
       " 'a web based dashboard for the filtered data retrieval of land records',\n",
       " 'integration of video conferencing data to the existing web app',\n",
       " 'design develop an app in retool which shows the progress of the added video',\n",
       " 'auvik connectwise integration in grafana',\n",
       " 'data integration and big data performance using elk stack',\n",
       " 'web data connector',\n",
       " 'an app for updating the email id of the user and stripe refund tool using retool',\n",
       " 'an ai ml based web application that detects the correctness of text in a given video',\n",
       " 'website tracking and insights using google analytics google tag manager',\n",
       " 'dashboard to track the analytics of the website using google analytics and google tag manager',\n",
       " 'power bi dashboard on operations transactions and marketing embedding the dashboard to web app',\n",
       " 'nft data automation looksrare and etl tool',\n",
       " 'optimize the data scraper program to easily accommodate large files and solve oom errors',\n",
       " 'making a robust way to sync data from airtables to mongodb using python etl solution',\n",
       " 'incident duration prediction infrastructure and real estate',\n",
       " 'statistical data analysis of reinforced concrete',\n",
       " 'database normalization segmentation with google data studio dashboard insights',\n",
       " 'power bi dashboard to drive insights from complex data to generate business insights',\n",
       " 'real time dashboard to monitor infrastructure activity and machines',\n",
       " 'electric vehicles ev load management system to forecast energy demand',\n",
       " 'power bi data driven map dashboard',\n",
       " 'google local service ads lsa leads dashboard',\n",
       " 'aws lex voice and chatbot',\n",
       " 'metabridges api decentraland integration',\n",
       " 'microsoft azure chatbot with luis language understanding',\n",
       " 'impact of news media and press on innovation startups and investments',\n",
       " 'aws quicksight reporting dashboard',\n",
       " 'google data studio dashboard for marketing ads and traction data',\n",
       " 'gangala in e commerce big data etl elt solution and data warehouse',\n",
       " 'big data solution to an online multivendor marketplace ecommerce business',\n",
       " 'creating a custom report and dashboard using the data got from atera api',\n",
       " 'azure data lake and power bi dashboard',\n",
       " 'google data studio pipeline with gcp mysql',\n",
       " 'quickbooks dashboard to find patterns in finance sales and forecasts',\n",
       " 'marketing sales and financial data business dashboard wink report',\n",
       " 'react native apps in the development portfolio',\n",
       " 'a leading firm website seo optimization',\n",
       " 'a leading hospitality firm in the usa website seo optimization',\n",
       " 'a leading firm in the usa website seo optimization',\n",
       " 'a leading musical instrumental website seo optimization',\n",
       " 'a leading firm in the usa seo and website optimization',\n",
       " 'immigration datawarehouse ai based recommendations',\n",
       " 'lipsync automation for celebrities and influencers',\n",
       " 'key audit matters predictive modeling',\n",
       " 'splitting of songs into its vocals and instrumental',\n",
       " 'ai and ml technologies to evaluate learning assessments',\n",
       " 'datawarehouse and recommendations engine for airbnb',\n",
       " 'real estate data warehouse',\n",
       " 'traction dashboards of marketing campaigns and posts',\n",
       " 'google local service ads lsa data warehouse',\n",
       " 'google local service ads missed calls and messages automation tool',\n",
       " 'marketing ads leads call status data tool to bigquery',\n",
       " 'marketing analytics to automate leads call status and reporting',\n",
       " 'callrail analytics leads report alert',\n",
       " 'marketing automation tool to notify lead details to clients over email and phone',\n",
       " 'data etl local service ads leads to bigquery',\n",
       " 'marbles stimulation using python',\n",
       " 'stocktwits data structurization',\n",
       " 'sentimental analysis on shareholder letter of companies',\n",
       " 'population and community survey of america',\n",
       " 'google lsa api data automation and dashboarding',\n",
       " 'healthcare data analysis',\n",
       " 'budget sales kpi dashboard using power bi',\n",
       " 'amazon buy bot an automation ai tool to auto checkouts']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input = pd.read_excel(\"C:/Users/sumit/Downloads/Input.xlsx\")\n",
    "input\n",
    "\n",
    "def get_article_names(urls):\n",
    "  titles = []\n",
    "  for i in range (len(urls)):\n",
    "    title = urls[i]\n",
    "    title_clean = title[title.index( \"m/\" ) + 2 :-1]. replace('-' , ' ')\n",
    "    titles.append(title_clean)\n",
    "  return titles\n",
    "\n",
    "urls =input[\"URL\"]\n",
    "urlsTitleDF = get_article_names(urls)\n",
    "urlsTitleDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9f2038a-c131-45ca-b614-8cc55380f1f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://insights.blackcoffer.com/how-people-diverted-to-telehealth-services-and-telemedicine\"\n",
    "\n",
    "page=requests.get(url , headers={\"User-Agent\": \"XY\"})  \n",
    "soup = BeautifulSoup(page.text , 'html.parser')\n",
    "#get title\n",
    "title = soup . find(\"h1\",attrs = { 'class' : 'entry-title'}).get_text()\n",
    "\n",
    "#get article text\n",
    "text = soup . find(attrs = { 'class' : 'td-post-content'}).get_text()\n",
    "# break into lines and remove leading and trailing space on each\n",
    "lines = (line.strip() for line in text.splitlines())\n",
    "# break multi-headlines into a line each\n",
    "chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "# drop blank lines\n",
    "text = '\\n'.join(chunk for chunk in chunks if chunk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48818e76-ba63-40a6-9687-d72122f6166d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a+', 'abound', 'abounds', 'abundance', 'abundant', 'accessable']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable', 'abominably']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "['ernst', 'young', 'deloitte', 'touche', 'kpmg', 'pricewaterhousecoopers']"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Loading positive words\n",
    "with open(positiveWordsFile,'r') as posfile:\n",
    "    positivewords=posfile.read().lower()\n",
    "positiveWordList=positivewords.split('\\n')\n",
    "\n",
    "\n",
    "# Loading negative words\n",
    "with open(nagitiveWordsFile ,'r' ,  encoding=\"ISO-8859-1\") as negfile:\n",
    "    negativeword=negfile.read().lower()\n",
    "negativeWordList=negativeword.split('\\n')\n",
    "\n",
    "#Loading stop words dictionary for removing stop words\n",
    "\n",
    "with open(stopWordsFile ,'r') as stop_words:\n",
    "    stopWords = stop_words.read().lower()\n",
    "stopWordList = stopWords.split('\\n')\n",
    "stopWordList[-1:] = []\n",
    "\n",
    "display( positiveWordList[:6]  , negativeWordList[:6] , stopWordList[:6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecfcd096-28c2-4fa6-9bc0-7f2c1343c18b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenizeing module and filtering tokens using stop words list, removing punctuations\n",
    "def tokenizer(text):\n",
    "    text = text.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    filtered_words = list(filter(lambda token: token not in stopWordList, tokens))\n",
    "    return filtered_words\n",
    "\n",
    "def positive_score (text):\n",
    "  posword=0\n",
    "  tokenphrase = tokenizer(text)\n",
    "  for word in tokenphrase :\n",
    "    if word in positiveWordList:\n",
    "       posword+=1\n",
    "      \n",
    "    retpos = posword\n",
    "    return retpos \n",
    "\n",
    "def negative_score (text):\n",
    "  negword=0\n",
    "  tokenphrase = tokenizer(text)\n",
    "  for word in tokenphrase :\n",
    "    if word in negativeWordList : negword +=1\n",
    "\n",
    "    retneg = negword \n",
    "    return retneg\n",
    "\n",
    "def polarity_score (positive_score , negative_score) :\n",
    "  return (positive_score - negative_score) / ((positive_score + negative_score) + 0.000001)\n",
    "#################################################\n",
    "def total_word_count(text):\n",
    "    tokens = tokenizer(text)\n",
    "    return len(tokens)\n",
    "#############################################\n",
    "def AverageSentenceLenght (text):\n",
    "  Wordcount = len(tokenizer (text))\n",
    "  SentenceCount = len (sent_tokenize(text))\n",
    "  if SentenceCount > 0 : Average_Sentence_Lenght = Wordcount / SentenceCount\n",
    "\n",
    "  avg = Average_Sentence_Lenght\n",
    "\n",
    "  return round(avg)\n",
    "\n",
    "\n",
    "# Counting complex words\n",
    "def complex_word_count(text):\n",
    "    tokens = tokenizer(text)\n",
    "    complexWord = 0\n",
    "    \n",
    "    for word in tokens:\n",
    "        vowels=0\n",
    "        if word.endswith(('es','ed')):\n",
    "            pass\n",
    "        else:\n",
    "            for w in word:\n",
    "                if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):\n",
    "                    vowels += 1\n",
    "            if(vowels > 2):\n",
    "                complexWord += 1\n",
    "    return complexWord\n",
    "\n",
    "def percentage_complex_word(text):\n",
    "    tokens = tokenizer(text)\n",
    "    complexWord = 0\n",
    "    complex_word_percentage = 0\n",
    "    \n",
    "    for word in tokens:\n",
    "        vowels=0\n",
    "        if word.endswith(('es','ed')):\n",
    "            pass\n",
    "        else:\n",
    "            for w in word:\n",
    "                if(w=='a' or w=='e' or w=='i' or w=='o' or w=='u'):\n",
    "                    vowels += 1\n",
    "            if(vowels > 2):\n",
    "                complexWord += 1\n",
    "    if len(tokens) != 0:\n",
    "        complex_word_percentage = complexWord/len(tokens)\n",
    "    \n",
    "    return complex_word_percentage\n",
    "\n",
    "def fog_index(averageSentenceLength, percentageComplexWord):\n",
    "    fogIndex = 0.4 * (averageSentenceLength + percentageComplexWord)\n",
    "    return fogIndex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b46bb4c-e885-418e-800a-48841b648fb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      https://insights.blackcoffer.com/ai-and-ml-bas...\n",
       "1      https://insights.blackcoffer.com/enhancing-fro...\n",
       "2      https://insights.blackcoffer.com/roas-dashboar...\n",
       "3      https://insights.blackcoffer.com/efficient-pro...\n",
       "4      https://insights.blackcoffer.com/development-o...\n",
       "                             ...                        \n",
       "142    https://insights.blackcoffer.com/population-an...\n",
       "143    https://insights.blackcoffer.com/google-lsa-ap...\n",
       "144    https://insights.blackcoffer.com/healthcare-da...\n",
       "145    https://insights.blackcoffer.com/budget-sales-...\n",
       "146    https://insights.blackcoffer.com/amazon-buy-bo...\n",
       "Name: URL, Length: 147, dtype: object"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "URLS = input [\"URL\"]\n",
    "URLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b6be3e6-8498-4585-8dc0-0bd772e845ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "corps = []\n",
    "for url in URLS:\n",
    "    try:\n",
    "        page = requests.get(url, headers={\"User-Agent\": \"XY\"}, timeout=20)\n",
    "        soup = BeautifulSoup(page.text, 'html.parser')\n",
    "\n",
    "        # get title safely\n",
    "        title_tag = soup.find(\"h1\", attrs={'class': 'entry-title'})\n",
    "        title = title_tag.get_text(strip=True) if title_tag else \"Title not found\"\n",
    "\n",
    "        # get article text safely\n",
    "        content_tag = soup.find(attrs={'class': 'td-post-content'})\n",
    "        if content_tag:\n",
    "            lines = (line.strip() for line in content_tag.get_text().splitlines())\n",
    "            chunks = (phrase.strip() for line in lines for phrase in line.split(\"  \"))\n",
    "            text = '\\n'.join(chunk for chunk in chunks if chunk)\n",
    "        else:\n",
    "            text = \"Content not found\"\n",
    "\n",
    "        corps.append({\"url\": url, \"title\": title, \"content\": text})\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error scraping {url}: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d20489f4-b210-4bd8-a5f1-68e39110f1ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.DataFrame(corps,urlsTitleDF)\n",
    "df = pd.DataFrame({'title':urlsTitleDF,'corps': corps})\n",
    "df[\"total_word_count\"] = df[\"corps\"].apply(lambda x: total_word_count(x['content']))\n",
    "df[\"percentage_complex_word\"] = df[\"corps\"].apply(lambda x: percentage_complex_word(x['content']))\n",
    "df[\"complex_word_count\"] = df[\"corps\"].apply(lambda x: complex_word_count(x['content']))\n",
    "df[\"AverageSentenceLenght\"] = df[\"corps\"].apply(lambda x: AverageSentenceLenght(x['content']))\n",
    "df[\"positive_score\"] = df[\"corps\"].apply(lambda x: positive_score(x['content']))\n",
    "df[\"negative_score\"] = df[\"corps\"].apply(lambda x: negative_score(x['content']))\n",
    "df[\"polarity_score\"] = np.vectorize(polarity_score)(df['positive_score'],df['negative_score'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "20f0c594-8459-459a-b9af-93df899851a1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>corps</th>\n",
       "      <th>total_word_count</th>\n",
       "      <th>percentage_complex_word</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>AverageSentenceLenght</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ai and ml based youtube analytics and content ...</td>\n",
       "      <td>{'url': 'https://insights.blackcoffer.com/ai-a...</td>\n",
       "      <td>274</td>\n",
       "      <td>0.248175</td>\n",
       "      <td>68</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enhancing front end features and functionality...</td>\n",
       "      <td>{'url': 'https://insights.blackcoffer.com/enha...</td>\n",
       "      <td>882</td>\n",
       "      <td>0.179138</td>\n",
       "      <td>158</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roas dashboard for campaign wise google ads bu...</td>\n",
       "      <td>{'url': 'https://insights.blackcoffer.com/roas...</td>\n",
       "      <td>437</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>114</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efficient processing and analysis of financial...</td>\n",
       "      <td>{'url': 'https://insights.blackcoffer.com/effi...</td>\n",
       "      <td>578</td>\n",
       "      <td>0.354671</td>\n",
       "      <td>205</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development of ea robot for automated trading</td>\n",
       "      <td>{'url': 'https://insights.blackcoffer.com/deve...</td>\n",
       "      <td>713</td>\n",
       "      <td>0.234222</td>\n",
       "      <td>167</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>population and community survey of america</td>\n",
       "      <td>{'url': 'https://insights.blackcoffer.com/popu...</td>\n",
       "      <td>919</td>\n",
       "      <td>0.218716</td>\n",
       "      <td>201</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>google lsa api data automation and dashboarding</td>\n",
       "      <td>{'url': 'https://insights.blackcoffer.com/goog...</td>\n",
       "      <td>1375</td>\n",
       "      <td>0.237818</td>\n",
       "      <td>327</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>healthcare data analysis</td>\n",
       "      <td>{'url': 'https://insights.blackcoffer.com/heal...</td>\n",
       "      <td>419</td>\n",
       "      <td>0.176611</td>\n",
       "      <td>74</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>budget sales kpi dashboard using power bi</td>\n",
       "      <td>{'url': 'https://insights.blackcoffer.com/budg...</td>\n",
       "      <td>106</td>\n",
       "      <td>0.198113</td>\n",
       "      <td>21</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>amazon buy bot an automation ai tool to auto c...</td>\n",
       "      <td>{'url': 'https://insights.blackcoffer.com/amaz...</td>\n",
       "      <td>125</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  \\\n",
       "0    ai and ml based youtube analytics and content ...   \n",
       "1    enhancing front end features and functionality...   \n",
       "2    roas dashboard for campaign wise google ads bu...   \n",
       "3    efficient processing and analysis of financial...   \n",
       "4        development of ea robot for automated trading   \n",
       "..                                                 ...   \n",
       "142         population and community survey of america   \n",
       "143    google lsa api data automation and dashboarding   \n",
       "144                           healthcare data analysis   \n",
       "145          budget sales kpi dashboard using power bi   \n",
       "146  amazon buy bot an automation ai tool to auto c...   \n",
       "\n",
       "                                                 corps  total_word_count  \\\n",
       "0    {'url': 'https://insights.blackcoffer.com/ai-a...               274   \n",
       "1    {'url': 'https://insights.blackcoffer.com/enha...               882   \n",
       "2    {'url': 'https://insights.blackcoffer.com/roas...               437   \n",
       "3    {'url': 'https://insights.blackcoffer.com/effi...               578   \n",
       "4    {'url': 'https://insights.blackcoffer.com/deve...               713   \n",
       "..                                                 ...               ...   \n",
       "142  {'url': 'https://insights.blackcoffer.com/popu...               919   \n",
       "143  {'url': 'https://insights.blackcoffer.com/goog...              1375   \n",
       "144  {'url': 'https://insights.blackcoffer.com/heal...               419   \n",
       "145  {'url': 'https://insights.blackcoffer.com/budg...               106   \n",
       "146  {'url': 'https://insights.blackcoffer.com/amaz...               125   \n",
       "\n",
       "     percentage_complex_word  complex_word_count  AverageSentenceLenght  \\\n",
       "0                   0.248175                  68                     46   \n",
       "1                   0.179138                 158                     24   \n",
       "2                   0.260870                 114                     24   \n",
       "3                   0.354671                 205                     21   \n",
       "4                   0.234222                 167                     17   \n",
       "..                       ...                 ...                    ...   \n",
       "142                 0.218716                 201                     26   \n",
       "143                 0.237818                 327                     21   \n",
       "144                 0.176611                  74                     30   \n",
       "145                 0.198113                  21                    106   \n",
       "146                 0.200000                  25                     18   \n",
       "\n",
       "     positive_score  negative_score  polarity_score  \n",
       "0                 0               0             0.0  \n",
       "1                 0               0             0.0  \n",
       "2                 0               0             0.0  \n",
       "3                 0               0             0.0  \n",
       "4                 0               0             0.0  \n",
       "..              ...             ...             ...  \n",
       "142               0               0             0.0  \n",
       "143               0               0             0.0  \n",
       "144               0               0             0.0  \n",
       "145               0               0             0.0  \n",
       "146               0               0             0.0  \n",
       "\n",
       "[147 rows x 9 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5da08995-d488-4818-a7af-3e6279fb5c4c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>total_word_count</th>\n",
       "      <th>percentage_complex_word</th>\n",
       "      <th>complex_word_count</th>\n",
       "      <th>AverageSentenceLenght</th>\n",
       "      <th>positive_score</th>\n",
       "      <th>negative_score</th>\n",
       "      <th>polarity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ai and ml based youtube analytics and content ...</td>\n",
       "      <td>274</td>\n",
       "      <td>0.248175</td>\n",
       "      <td>68</td>\n",
       "      <td>46</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>enhancing front end features and functionality...</td>\n",
       "      <td>882</td>\n",
       "      <td>0.179138</td>\n",
       "      <td>158</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>roas dashboard for campaign wise google ads bu...</td>\n",
       "      <td>437</td>\n",
       "      <td>0.260870</td>\n",
       "      <td>114</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>efficient processing and analysis of financial...</td>\n",
       "      <td>578</td>\n",
       "      <td>0.354671</td>\n",
       "      <td>205</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>development of ea robot for automated trading</td>\n",
       "      <td>713</td>\n",
       "      <td>0.234222</td>\n",
       "      <td>167</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>142</th>\n",
       "      <td>population and community survey of america</td>\n",
       "      <td>919</td>\n",
       "      <td>0.218716</td>\n",
       "      <td>201</td>\n",
       "      <td>26</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>google lsa api data automation and dashboarding</td>\n",
       "      <td>1375</td>\n",
       "      <td>0.237818</td>\n",
       "      <td>327</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>healthcare data analysis</td>\n",
       "      <td>419</td>\n",
       "      <td>0.176611</td>\n",
       "      <td>74</td>\n",
       "      <td>30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>budget sales kpi dashboard using power bi</td>\n",
       "      <td>106</td>\n",
       "      <td>0.198113</td>\n",
       "      <td>21</td>\n",
       "      <td>106</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>amazon buy bot an automation ai tool to auto c...</td>\n",
       "      <td>125</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>25</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>147 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 title  total_word_count  \\\n",
       "0    ai and ml based youtube analytics and content ...               274   \n",
       "1    enhancing front end features and functionality...               882   \n",
       "2    roas dashboard for campaign wise google ads bu...               437   \n",
       "3    efficient processing and analysis of financial...               578   \n",
       "4        development of ea robot for automated trading               713   \n",
       "..                                                 ...               ...   \n",
       "142         population and community survey of america               919   \n",
       "143    google lsa api data automation and dashboarding              1375   \n",
       "144                           healthcare data analysis               419   \n",
       "145          budget sales kpi dashboard using power bi               106   \n",
       "146  amazon buy bot an automation ai tool to auto c...               125   \n",
       "\n",
       "     percentage_complex_word  complex_word_count  AverageSentenceLenght  \\\n",
       "0                   0.248175                  68                     46   \n",
       "1                   0.179138                 158                     24   \n",
       "2                   0.260870                 114                     24   \n",
       "3                   0.354671                 205                     21   \n",
       "4                   0.234222                 167                     17   \n",
       "..                       ...                 ...                    ...   \n",
       "142                 0.218716                 201                     26   \n",
       "143                 0.237818                 327                     21   \n",
       "144                 0.176611                  74                     30   \n",
       "145                 0.198113                  21                    106   \n",
       "146                 0.200000                  25                     18   \n",
       "\n",
       "     positive_score  negative_score  polarity_score  \n",
       "0                 0               0             0.0  \n",
       "1                 0               0             0.0  \n",
       "2                 0               0             0.0  \n",
       "3                 0               0             0.0  \n",
       "4                 0               0             0.0  \n",
       "..              ...             ...             ...  \n",
       "142               0               0             0.0  \n",
       "143               0               0             0.0  \n",
       "144               0               0             0.0  \n",
       "145               0               0             0.0  \n",
       "146               0               0             0.0  \n",
       "\n",
       "[147 rows x 8 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final = df.drop(\"corps\", axis=1)\n",
    "final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "821fd985-6ae9-4fbc-a349-27d7548b86c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv('Output_Data_Structure.csv', index=False, encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa50666-8ad3-44f8-9ca3-c3be9a6e6789",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10 (tf-env)",
   "language": "python",
   "name": "tf-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
